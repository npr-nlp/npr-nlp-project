{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe1ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the things\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle\n",
    "import acquire\n",
    "from prepare import basic_clean, tokenize, lemmatize, stem, remove_stopwords, prep_string_data#, split_data\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07320e93",
   "metadata": {},
   "source": [
    "# SPLITTING UP THE DATA HERE BASED ON A TSA APPROACH\n",
    "### Other of our explorations might work slightly differently, if we do a prediction model or topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08f5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('npr_corpus.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45972e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has 1889857 rows and 12 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id_num</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>program</th>\n",
       "      <th>title</th>\n",
       "      <th>is_host</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>vader</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57264</td>\n",
       "      <td>9</td>\n",
       "      <td>ms. loren mooney (editor-in-chief, bicycling m...</td>\n",
       "      <td>It's a 2,200-mile race. To give some sense of ...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>False</td>\n",
       "      <td>it s a 2,200 mile race. to give some sense of ...</td>\n",
       "      <td>it s a 2,200 mile race. to give some sense of ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57264</td>\n",
       "      <td>10</td>\n",
       "      <td>ms. loren mooney (editor-in-chief, bicycling m...</td>\n",
       "      <td>So for a top competitor like Lance to try to m...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>False</td>\n",
       "      <td>so for a top competitor like lance to try to m...</td>\n",
       "      <td>so for a top competitor like lance to try to m...</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57264</td>\n",
       "      <td>11</td>\n",
       "      <td>neal conan, host</td>\n",
       "      <td>So in every team, presumably there's one star,...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>True</td>\n",
       "      <td>so in every team , presumably there s one star...</td>\n",
       "      <td>so in every team , presumably there s one star...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57264</td>\n",
       "      <td>12</td>\n",
       "      <td>ms. loren mooney (editor-in-chief, bicycling m...</td>\n",
       "      <td>That's right. Each team has nine riders. And w...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>False</td>\n",
       "      <td>that s right. each team has nine riders. and w...</td>\n",
       "      <td>that s right. each team ha nine riders. and wh...</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57264</td>\n",
       "      <td>13</td>\n",
       "      <td>neal conan, host</td>\n",
       "      <td>So slipstream, this is like drafting in car ra...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>True</td>\n",
       "      <td>so slipstream , this is like drafting in car r...</td>\n",
       "      <td>so slipstream , this is like drafting in car r...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id_num  utterance_order  \\\n",
       "0         57264                9   \n",
       "1         57264               10   \n",
       "2         57264               11   \n",
       "3         57264               12   \n",
       "4         57264               13   \n",
       "\n",
       "                                             speaker  \\\n",
       "0  ms. loren mooney (editor-in-chief, bicycling m...   \n",
       "1  ms. loren mooney (editor-in-chief, bicycling m...   \n",
       "2                                   neal conan, host   \n",
       "3  ms. loren mooney (editor-in-chief, bicycling m...   \n",
       "4                                   neal conan, host   \n",
       "\n",
       "                                           utterance             program  \\\n",
       "0  It's a 2,200-mile race. To give some sense of ...  talk of the nation   \n",
       "1  So for a top competitor like Lance to try to m...  talk of the nation   \n",
       "2  So in every team, presumably there's one star,...  talk of the nation   \n",
       "3  That's right. Each team has nine riders. And w...  talk of the nation   \n",
       "4  So slipstream, this is like drafting in car ra...  talk of the nation   \n",
       "\n",
       "                             title  is_host  \\\n",
       "0  how to watch the tour de france    False   \n",
       "1  how to watch the tour de france    False   \n",
       "2  how to watch the tour de france     True   \n",
       "3  how to watch the tour de france    False   \n",
       "4  how to watch the tour de france     True   \n",
       "\n",
       "                                               clean  \\\n",
       "0  it s a 2,200 mile race. to give some sense of ...   \n",
       "1  so for a top competitor like lance to try to m...   \n",
       "2  so in every team , presumably there s one star...   \n",
       "3  that s right. each team has nine riders. and w...   \n",
       "4  so slipstream , this is like drafting in car r...   \n",
       "\n",
       "                                          lemmatized   vader        date  \n",
       "0  it s a 2,200 mile race. to give some sense of ...  0.0000  2010-07-12  \n",
       "1  so for a top competitor like lance to try to m...  0.9346  2010-07-12  \n",
       "2  so in every team , presumably there s one star...  0.7096  2010-07-12  \n",
       "3  that s right. each team ha nine riders. and wh...  0.9274  2010-07-12  \n",
       "4  so slipstream , this is like drafting in car r...  0.3612  2010-07-12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle.get_npr_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be99cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id_num</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>program</th>\n",
       "      <th>title</th>\n",
       "      <th>is_host</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>vader</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13231</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>He is in cahoots with a foreign government to ...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>he is in cahoots with a foreign government to ...</td>\n",
       "      <td>he is in cahoot with a foreign government to m...</td>\n",
       "      <td>-0.8176</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13232</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Let's hear now from another Democrat. Tom Mali...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>let s hear now from another democrat. tom mali...</td>\n",
       "      <td>let s hear now from another democrat. tom mali...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13233</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>Good morning.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>good morning .</td>\n",
       "      <td>good morning .</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13234</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>I'd like first to get your response to the Tru...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>i d like first to get your response to the tru...</td>\n",
       "      <td>i d like first to get your response to the tru...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>Well, first of all, it's illegal. We have a ve...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>well , first of all , it s illegal. we have a ...</td>\n",
       "      <td>well , first of all , it s illegal. we have a ...</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Now, we should explain that this has to do, ac...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>now , we should explain that this has to do , ...</td>\n",
       "      <td>now , we should explain that this ha to do , a...</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>Look. I think there is a very, very big leap b...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>look. i think there is a very , very big leap ...</td>\n",
       "      <td>look. i think there is a very , very big leap ...</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And you say, if it's true...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>and you say , if it s true ...</td>\n",
       "      <td>and you say , if it s true ...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>And yes, impeachable.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>and yes , impeachable .</td>\n",
       "      <td>and yes , impeachable .</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>You say, if it's true, what powers does the Ho...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>you say , if it s true , what powers does the ...</td>\n",
       "      <td>you say , if it s true , what power doe the ho...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>It does have to be corroborated. We can't impe...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>it does have to be corroborated. we can t impe...</td>\n",
       "      <td>it doe have to be corroborated. we can t impea...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13242</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Let me ask you, congressman. There are a numbe...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>let me ask you , congressman. there are a numb...</td>\n",
       "      <td>let me ask you , congressman. there are a numb...</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243</th>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>I think it is absolutely imperative for the Ho...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>i think it is absolutely imperative for the ho...</td>\n",
       "      <td>i think it is absolutely imperative for the ho...</td>\n",
       "      <td>0.6088</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13244</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And very...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>and very ...</td>\n",
       "      <td>and very ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13245</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>That is not American democracy.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>that is not american democracy .</td>\n",
       "      <td>that is not american democracy .</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13246</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Very briefly, congressman, are you hearing any...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>very briefly , congressman , are you hearing a...</td>\n",
       "      <td>very briefly , congressman , are you hearing a...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13247</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>I'm - so far, pretty much silence, but I also ...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>i m so far , pretty much silence , but i also ...</td>\n",
       "      <td>i m so far , pretty much silence , but i also ...</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13248</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>OK.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>ok .</td>\n",
       "      <td>ok .</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>tom malinowski</td>\n",
       "      <td>...Will tolerate. You know, we can't base our ...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>False</td>\n",
       "      <td>... will tolerate. you know , we can t base ou...</td>\n",
       "      <td>... will tolerate. you know , we can t base ou...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And we'll have to leave it there. Representati...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>n.j. democrat on reported whistleblower compla...</td>\n",
       "      <td>True</td>\n",
       "      <td>and we ll have to leave it there. representati...</td>\n",
       "      <td>and we ll have to leave it there. representati...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554787</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Come with concrete plans, not beautiful speech...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>come with concrete plans , not beautiful speec...</td>\n",
       "      <td>come with concrete plan , not beautiful speech...</td>\n",
       "      <td>-0.6305</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554788</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>We're going to hear from two participants now....</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>we re going to hear from two participants now....</td>\n",
       "      <td>we re going to hear from two participant now. ...</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554789</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>Thank you so much.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>thank you so much .</td>\n",
       "      <td>thank you so much .</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554790</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And we're also joined by Minal Pathak. She is ...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>and we re also joined by minal pathak. she is ...</td>\n",
       "      <td>and we re also joined by minal pathak. she is ...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554791</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>Thank you very much, Melissa.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>thank you very much , melissa .</td>\n",
       "      <td>thank you very much , melissa .</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554792</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And Mayor Helps, let me start with you. Your c...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>and mayor helps , let me start with you. your ...</td>\n",
       "      <td>and mayor help , let me start with you. your c...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554793</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>We are seeing more flooding than in past years...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>we are seeing more flooding than in past years...</td>\n",
       "      <td>we are seeing more flooding than in past year ...</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554794</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And let me turn to you, Minal Pathak. In your ...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>and let me turn to you , minal pathak. in your...</td>\n",
       "      <td>and let me turn to you , minal pathak. in your...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554795</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>I think for Ahmedabad, we are witnessing extre...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>i think for ahmedabad , we are witnessing extr...</td>\n",
       "      <td>i think for ahmedabad , we are witnessing extr...</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554796</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Forty-six or 47 degrees Celsius - that would t...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>forty six or 47 degrees celsius that would tra...</td>\n",
       "      <td>forty six or 47 degree celsius that would tran...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554797</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>That's correct. And I think one of the challen...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>that s correct. and i think one of the challen...</td>\n",
       "      <td>that s correct. and i think one of the challen...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554798</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Mayor Helps, what strategies are you trying to...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>mayor helps , what strategies are you trying t...</td>\n",
       "      <td>mayor help , what strategy are you trying to p...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554799</th>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>Well, I think this is why it's so thrilling to...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>well , i think this is why it s so thrilling t...</td>\n",
       "      <td>well , i think this is why it s so thrilling t...</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554800</th>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>We're going to, you know, have to do some of t...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>we re going to , you know , have to do some of...</td>\n",
       "      <td>we re going to , you know , have to do some of...</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554801</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>We also took a bold move a couple of years ago...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>we also took a bold move a couple of years ago...</td>\n",
       "      <td>we also took a bold move a couple of year ago ...</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554802</th>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And Minal Pathak, we're hearing Mayor Phelps (...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>and minal pathak , we re hearing mayor phelps ...</td>\n",
       "      <td>and minal pathak , we re hearing mayor phelps ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554803</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>So Ahmedabad city took - I mean, it's the lead...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>so ahmedabad city took i mean , it s the leade...</td>\n",
       "      <td>so ahmedabad city took i mean , it s the leade...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554804</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>The other one is the ambitious tree plantation...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>the other one is the ambitious tree plantation...</td>\n",
       "      <td>the other one is the ambitious tree plantation...</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554805</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>And I think one of the challenges we have is t...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>and i think one of the challenges we have is t...</td>\n",
       "      <td>and i think one of the challenge we have is th...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554806</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>We have, of course, seen no shortage of climat...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>we have , of course , seen no shortage of clim...</td>\n",
       "      <td>we have , of course , seen no shortage of clim...</td>\n",
       "      <td>-0.5803</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554807</th>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>I was at the climate strike on Friday, and tha...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>i was at the climate strike on friday , and th...</td>\n",
       "      <td>i wa at the climate strike on friday , and tha...</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554808</th>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>And Mayor Helps, what gives you hope?</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>and mayor helps , what gives you hope ?</td>\n",
       "      <td>and mayor help , what give you hope ?</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554809</th>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>Yeah, I completely agree. What gives me hope i...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>yeah , i completely agree. what gives me hope ...</td>\n",
       "      <td>yeah , i completely agree. what give me hope i...</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554810</th>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>What will be really, really important from my ...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>what will be really , really important from my...</td>\n",
       "      <td>what will be really , really important from my...</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554811</th>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>We heard there from Lisa Helps - she is the ma...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>we heard there from lisa helps she is the mayo...</td>\n",
       "      <td>we heard there from lisa help she is the mayor...</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554812</th>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Thanks so much to you both for taking the time...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>True</td>\n",
       "      <td>thanks so much to you both for taking the time...</td>\n",
       "      <td>thanks so much to you both for taking the time...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554813</th>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>lisa helps</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>thank you .</td>\n",
       "      <td>thank you .</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554814</th>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>minal pathak</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>ahead of climate summit, 2 views from cities i...</td>\n",
       "      <td>False</td>\n",
       "      <td>thank you very much .</td>\n",
       "      <td>thank you very much .</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634414</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>If you stand outside the old DeKalb County Cou...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>barred from removing confederate monument, cou...</td>\n",
       "      <td>True</td>\n",
       "      <td>if you stand outside the old dekalb county cou...</td>\n",
       "      <td>if you stand outside the old dekalb county cou...</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634415</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>melissa block, host</td>\n",
       "      <td>Well, as of this month, there's now a contextu...</td>\n",
       "      <td>weekend edition sunday</td>\n",
       "      <td>barred from removing confederate monument, cou...</td>\n",
       "      <td>True</td>\n",
       "      <td>well , as of this month , there s now a contex...</td>\n",
       "      <td>well , a of this month , there s now a context...</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         story_id_num  utterance_order              speaker  \\\n",
       "13231              17                1  melissa block, host   \n",
       "13232              17                2  melissa block, host   \n",
       "13233              17                3       tom malinowski   \n",
       "13234              17                4  melissa block, host   \n",
       "13235              17                5       tom malinowski   \n",
       "13236              17                6  melissa block, host   \n",
       "13237              17                7       tom malinowski   \n",
       "13238              17                8  melissa block, host   \n",
       "13239              17                9       tom malinowski   \n",
       "13240              17               10  melissa block, host   \n",
       "13241              17               11       tom malinowski   \n",
       "13242              17               12  melissa block, host   \n",
       "13243              17               13       tom malinowski   \n",
       "13244              17               14  melissa block, host   \n",
       "13245              17               15       tom malinowski   \n",
       "13246              17               16  melissa block, host   \n",
       "13247              17               17       tom malinowski   \n",
       "13248              17               18  melissa block, host   \n",
       "13249              17               19       tom malinowski   \n",
       "13250              17               20  melissa block, host   \n",
       "2554787            18                1  melissa block, host   \n",
       "2554788            18                2  melissa block, host   \n",
       "2554789            18                3           lisa helps   \n",
       "2554790            18                4  melissa block, host   \n",
       "2554791            18                5         minal pathak   \n",
       "2554792            18                6  melissa block, host   \n",
       "2554793            18                7           lisa helps   \n",
       "2554794            18                8  melissa block, host   \n",
       "2554795            18                9         minal pathak   \n",
       "2554796            18               10  melissa block, host   \n",
       "2554797            18               11         minal pathak   \n",
       "2554798            18               12  melissa block, host   \n",
       "2554799            18               13           lisa helps   \n",
       "2554800            18               14           lisa helps   \n",
       "2554801            18               15           lisa helps   \n",
       "2554802            18               16  melissa block, host   \n",
       "2554803            18               17         minal pathak   \n",
       "2554804            18               18         minal pathak   \n",
       "2554805            18               19         minal pathak   \n",
       "2554806            18               20  melissa block, host   \n",
       "2554807            18               21         minal pathak   \n",
       "2554808            18               22  melissa block, host   \n",
       "2554809            18               23           lisa helps   \n",
       "2554810            18               24           lisa helps   \n",
       "2554811            18               25  melissa block, host   \n",
       "2554812            18               26  melissa block, host   \n",
       "2554813            18               27           lisa helps   \n",
       "2554814            18               28         minal pathak   \n",
       "1634414            19                1  melissa block, host   \n",
       "1634415            19                2  melissa block, host   \n",
       "\n",
       "                                                 utterance  \\\n",
       "13231    He is in cahoots with a foreign government to ...   \n",
       "13232    Let's hear now from another Democrat. Tom Mali...   \n",
       "13233                                        Good morning.   \n",
       "13234    I'd like first to get your response to the Tru...   \n",
       "13235    Well, first of all, it's illegal. We have a ve...   \n",
       "13236    Now, we should explain that this has to do, ac...   \n",
       "13237    Look. I think there is a very, very big leap b...   \n",
       "13238                         And you say, if it's true...   \n",
       "13239                                And yes, impeachable.   \n",
       "13240    You say, if it's true, what powers does the Ho...   \n",
       "13241    It does have to be corroborated. We can't impe...   \n",
       "13242    Let me ask you, congressman. There are a numbe...   \n",
       "13243    I think it is absolutely imperative for the Ho...   \n",
       "13244                                          And very...   \n",
       "13245                      That is not American democracy.   \n",
       "13246    Very briefly, congressman, are you hearing any...   \n",
       "13247    I'm - so far, pretty much silence, but I also ...   \n",
       "13248                                                  OK.   \n",
       "13249    ...Will tolerate. You know, we can't base our ...   \n",
       "13250    And we'll have to leave it there. Representati...   \n",
       "2554787  Come with concrete plans, not beautiful speech...   \n",
       "2554788  We're going to hear from two participants now....   \n",
       "2554789                                 Thank you so much.   \n",
       "2554790  And we're also joined by Minal Pathak. She is ...   \n",
       "2554791                      Thank you very much, Melissa.   \n",
       "2554792  And Mayor Helps, let me start with you. Your c...   \n",
       "2554793  We are seeing more flooding than in past years...   \n",
       "2554794  And let me turn to you, Minal Pathak. In your ...   \n",
       "2554795  I think for Ahmedabad, we are witnessing extre...   \n",
       "2554796  Forty-six or 47 degrees Celsius - that would t...   \n",
       "2554797  That's correct. And I think one of the challen...   \n",
       "2554798  Mayor Helps, what strategies are you trying to...   \n",
       "2554799  Well, I think this is why it's so thrilling to...   \n",
       "2554800  We're going to, you know, have to do some of t...   \n",
       "2554801  We also took a bold move a couple of years ago...   \n",
       "2554802  And Minal Pathak, we're hearing Mayor Phelps (...   \n",
       "2554803  So Ahmedabad city took - I mean, it's the lead...   \n",
       "2554804  The other one is the ambitious tree plantation...   \n",
       "2554805  And I think one of the challenges we have is t...   \n",
       "2554806  We have, of course, seen no shortage of climat...   \n",
       "2554807  I was at the climate strike on Friday, and tha...   \n",
       "2554808              And Mayor Helps, what gives you hope?   \n",
       "2554809  Yeah, I completely agree. What gives me hope i...   \n",
       "2554810  What will be really, really important from my ...   \n",
       "2554811  We heard there from Lisa Helps - she is the ma...   \n",
       "2554812  Thanks so much to you both for taking the time...   \n",
       "2554813                                         Thank you.   \n",
       "2554814                               Thank you very much.   \n",
       "1634414  If you stand outside the old DeKalb County Cou...   \n",
       "1634415  Well, as of this month, there's now a contextu...   \n",
       "\n",
       "                        program  \\\n",
       "13231    weekend edition sunday   \n",
       "13232    weekend edition sunday   \n",
       "13233    weekend edition sunday   \n",
       "13234    weekend edition sunday   \n",
       "13235    weekend edition sunday   \n",
       "13236    weekend edition sunday   \n",
       "13237    weekend edition sunday   \n",
       "13238    weekend edition sunday   \n",
       "13239    weekend edition sunday   \n",
       "13240    weekend edition sunday   \n",
       "13241    weekend edition sunday   \n",
       "13242    weekend edition sunday   \n",
       "13243    weekend edition sunday   \n",
       "13244    weekend edition sunday   \n",
       "13245    weekend edition sunday   \n",
       "13246    weekend edition sunday   \n",
       "13247    weekend edition sunday   \n",
       "13248    weekend edition sunday   \n",
       "13249    weekend edition sunday   \n",
       "13250    weekend edition sunday   \n",
       "2554787  weekend edition sunday   \n",
       "2554788  weekend edition sunday   \n",
       "2554789  weekend edition sunday   \n",
       "2554790  weekend edition sunday   \n",
       "2554791  weekend edition sunday   \n",
       "2554792  weekend edition sunday   \n",
       "2554793  weekend edition sunday   \n",
       "2554794  weekend edition sunday   \n",
       "2554795  weekend edition sunday   \n",
       "2554796  weekend edition sunday   \n",
       "2554797  weekend edition sunday   \n",
       "2554798  weekend edition sunday   \n",
       "2554799  weekend edition sunday   \n",
       "2554800  weekend edition sunday   \n",
       "2554801  weekend edition sunday   \n",
       "2554802  weekend edition sunday   \n",
       "2554803  weekend edition sunday   \n",
       "2554804  weekend edition sunday   \n",
       "2554805  weekend edition sunday   \n",
       "2554806  weekend edition sunday   \n",
       "2554807  weekend edition sunday   \n",
       "2554808  weekend edition sunday   \n",
       "2554809  weekend edition sunday   \n",
       "2554810  weekend edition sunday   \n",
       "2554811  weekend edition sunday   \n",
       "2554812  weekend edition sunday   \n",
       "2554813  weekend edition sunday   \n",
       "2554814  weekend edition sunday   \n",
       "1634414  weekend edition sunday   \n",
       "1634415  weekend edition sunday   \n",
       "\n",
       "                                                     title  is_host  \\\n",
       "13231    n.j. democrat on reported whistleblower compla...     True   \n",
       "13232    n.j. democrat on reported whistleblower compla...     True   \n",
       "13233    n.j. democrat on reported whistleblower compla...    False   \n",
       "13234    n.j. democrat on reported whistleblower compla...     True   \n",
       "13235    n.j. democrat on reported whistleblower compla...    False   \n",
       "13236    n.j. democrat on reported whistleblower compla...     True   \n",
       "13237    n.j. democrat on reported whistleblower compla...    False   \n",
       "13238    n.j. democrat on reported whistleblower compla...     True   \n",
       "13239    n.j. democrat on reported whistleblower compla...    False   \n",
       "13240    n.j. democrat on reported whistleblower compla...     True   \n",
       "13241    n.j. democrat on reported whistleblower compla...    False   \n",
       "13242    n.j. democrat on reported whistleblower compla...     True   \n",
       "13243    n.j. democrat on reported whistleblower compla...    False   \n",
       "13244    n.j. democrat on reported whistleblower compla...     True   \n",
       "13245    n.j. democrat on reported whistleblower compla...    False   \n",
       "13246    n.j. democrat on reported whistleblower compla...     True   \n",
       "13247    n.j. democrat on reported whistleblower compla...    False   \n",
       "13248    n.j. democrat on reported whistleblower compla...     True   \n",
       "13249    n.j. democrat on reported whistleblower compla...    False   \n",
       "13250    n.j. democrat on reported whistleblower compla...     True   \n",
       "2554787  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554788  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554789  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554790  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554791  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554792  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554793  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554794  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554795  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554796  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554797  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554798  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554799  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554800  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554801  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554802  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554803  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554804  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554805  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554806  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554807  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554808  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554809  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554810  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554811  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554812  ahead of climate summit, 2 views from cities i...     True   \n",
       "2554813  ahead of climate summit, 2 views from cities i...    False   \n",
       "2554814  ahead of climate summit, 2 views from cities i...    False   \n",
       "1634414  barred from removing confederate monument, cou...     True   \n",
       "1634415  barred from removing confederate monument, cou...     True   \n",
       "\n",
       "                                                     clean  \\\n",
       "13231    he is in cahoots with a foreign government to ...   \n",
       "13232    let s hear now from another democrat. tom mali...   \n",
       "13233                                       good morning .   \n",
       "13234    i d like first to get your response to the tru...   \n",
       "13235    well , first of all , it s illegal. we have a ...   \n",
       "13236    now , we should explain that this has to do , ...   \n",
       "13237    look. i think there is a very , very big leap ...   \n",
       "13238                       and you say , if it s true ...   \n",
       "13239                              and yes , impeachable .   \n",
       "13240    you say , if it s true , what powers does the ...   \n",
       "13241    it does have to be corroborated. we can t impe...   \n",
       "13242    let me ask you , congressman. there are a numb...   \n",
       "13243    i think it is absolutely imperative for the ho...   \n",
       "13244                                         and very ...   \n",
       "13245                     that is not american democracy .   \n",
       "13246    very briefly , congressman , are you hearing a...   \n",
       "13247    i m so far , pretty much silence , but i also ...   \n",
       "13248                                                 ok .   \n",
       "13249    ... will tolerate. you know , we can t base ou...   \n",
       "13250    and we ll have to leave it there. representati...   \n",
       "2554787  come with concrete plans , not beautiful speec...   \n",
       "2554788  we re going to hear from two participants now....   \n",
       "2554789                                thank you so much .   \n",
       "2554790  and we re also joined by minal pathak. she is ...   \n",
       "2554791                    thank you very much , melissa .   \n",
       "2554792  and mayor helps , let me start with you. your ...   \n",
       "2554793  we are seeing more flooding than in past years...   \n",
       "2554794  and let me turn to you , minal pathak. in your...   \n",
       "2554795  i think for ahmedabad , we are witnessing extr...   \n",
       "2554796  forty six or 47 degrees celsius that would tra...   \n",
       "2554797  that s correct. and i think one of the challen...   \n",
       "2554798  mayor helps , what strategies are you trying t...   \n",
       "2554799  well , i think this is why it s so thrilling t...   \n",
       "2554800  we re going to , you know , have to do some of...   \n",
       "2554801  we also took a bold move a couple of years ago...   \n",
       "2554802  and minal pathak , we re hearing mayor phelps ...   \n",
       "2554803  so ahmedabad city took i mean , it s the leade...   \n",
       "2554804  the other one is the ambitious tree plantation...   \n",
       "2554805  and i think one of the challenges we have is t...   \n",
       "2554806  we have , of course , seen no shortage of clim...   \n",
       "2554807  i was at the climate strike on friday , and th...   \n",
       "2554808            and mayor helps , what gives you hope ?   \n",
       "2554809  yeah , i completely agree. what gives me hope ...   \n",
       "2554810  what will be really , really important from my...   \n",
       "2554811  we heard there from lisa helps she is the mayo...   \n",
       "2554812  thanks so much to you both for taking the time...   \n",
       "2554813                                        thank you .   \n",
       "2554814                              thank you very much .   \n",
       "1634414  if you stand outside the old dekalb county cou...   \n",
       "1634415  well , as of this month , there s now a contex...   \n",
       "\n",
       "                                                lemmatized   vader        date  \n",
       "13231    he is in cahoot with a foreign government to m... -0.8176  2019-09-22  \n",
       "13232    let s hear now from another democrat. tom mali...  0.4404  2019-09-22  \n",
       "13233                                       good morning .  0.4404  2019-09-22  \n",
       "13234    i d like first to get your response to the tru...  0.3612  2019-09-22  \n",
       "13235    well , first of all , it s illegal. we have a ...  0.8680  2019-09-22  \n",
       "13236    now , we should explain that this ha to do , a...  0.5106  2019-09-22  \n",
       "13237    look. i think there is a very , very big leap ...  0.7783  2019-09-22  \n",
       "13238                       and you say , if it s true ...  0.4215  2019-09-22  \n",
       "13239                              and yes , impeachable .  0.4019  2019-09-22  \n",
       "13240    you say , if it s true , what power doe the ho...  0.4215  2019-09-22  \n",
       "13241    it doe have to be corroborated. we can t impea...  0.0000  2019-09-22  \n",
       "13242    let me ask you , congressman. there are a numb...  0.7236  2019-09-22  \n",
       "13243    i think it is absolutely imperative for the ho...  0.6088  2019-09-22  \n",
       "13244                                         and very ...  0.0000  2019-09-22  \n",
       "13245                     that is not american democracy .  0.0000  2019-09-22  \n",
       "13246    very briefly , congressman , are you hearing a...  0.0000  2019-09-22  \n",
       "13247    i m so far , pretty much silence , but i also ...  0.3047  2019-09-22  \n",
       "13248                                                 ok .  0.2960  2019-09-22  \n",
       "13249    ... will tolerate. you know , we can t base ou...  0.4019  2019-09-22  \n",
       "13250    and we ll have to leave it there. representati...  0.4019  2019-09-22  \n",
       "2554787  come with concrete plan , not beautiful speech... -0.6305  2019-09-22  \n",
       "2554788  we re going to hear from two participant now. ...  0.8126  2019-09-22  \n",
       "2554789                                thank you so much .  0.3612  2019-09-22  \n",
       "2554790  and we re also joined by minal pathak. she is ...  0.6249  2019-09-22  \n",
       "2554791                    thank you very much , melissa .  0.3612  2019-09-22  \n",
       "2554792  and mayor help , let me start with you. your c...  0.4019  2019-09-22  \n",
       "2554793  we are seeing more flooding than in past year ...  0.3299  2019-09-22  \n",
       "2554794  and let me turn to you , minal pathak. in your...  0.0000  2019-09-22  \n",
       "2554795  i think for ahmedabad , we are witnessing extr...  0.3353  2019-09-22  \n",
       "2554796  forty six or 47 degree celsius that would tran...  0.0000  2019-09-22  \n",
       "2554797  that s correct. and i think one of the challen...  0.0772  2019-09-22  \n",
       "2554798  mayor help , what strategy are you trying to p...  0.4019  2019-09-22  \n",
       "2554799  well , i think this is why it s so thrilling t...  0.7896  2019-09-22  \n",
       "2554800  we re going to , you know , have to do some of...  0.6486  2019-09-22  \n",
       "2554801  we also took a bold move a couple of year ago ...  0.8988  2019-09-22  \n",
       "2554802  and minal pathak , we re hearing mayor phelps ...  0.0000  2019-09-22  \n",
       "2554803  so ahmedabad city took i mean , it s the leade... -0.3400  2019-09-22  \n",
       "2554804  the other one is the ambitious tree plantation...  0.9186  2019-09-22  \n",
       "2554805  and i think one of the challenge we have is th...  0.5267  2019-09-22  \n",
       "2554806  we have , of course , seen no shortage of clim... -0.5803  2019-09-22  \n",
       "2554807  i wa at the climate strike on friday , and tha...  0.5965  2019-09-22  \n",
       "2554808              and mayor help , what give you hope ?  0.6808  2019-09-22  \n",
       "2554809  yeah , i completely agree. what give me hope i...  0.9703  2019-09-22  \n",
       "2554810  what will be really , really important from my...  0.8273  2019-09-22  \n",
       "2554811  we heard there from lisa help she is the mayor...  0.7650  2019-09-22  \n",
       "2554812  thanks so much to you both for taking the time...  0.4404  2019-09-22  \n",
       "2554813                                        thank you .  0.3612  2019-09-22  \n",
       "2554814                              thank you very much .  0.3612  2019-09-22  \n",
       "1634414  if you stand outside the old dekalb county cou...  0.6486  2019-09-22  \n",
       "1634415  well , a of this month , there s now a context...  0.7430  2019-09-22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.sort_values(by=['episode_id','episode_order'])[0:50]\n",
    "df.sort_values(by=['story_id_num','utterance_order'])[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22b75c",
   "metadata": {},
   "source": [
    "## Ok, since we already have utterance order, we can just use that as a feature\n",
    "## Moving on to utterance length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb17921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's a 2,200-mile race. To give some sense of perspective, that's roughly the distance between Washington, D.C. and Las Vegas. They do it over the course of three weeks at very fast speeds. But incredibly, oftentimes the distance between first and second is somewhere between and one and three minutes.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.utterance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df23cc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.utterance[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b9dc88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id_num</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>program</th>\n",
       "      <th>title</th>\n",
       "      <th>is_host</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>vader</th>\n",
       "      <th>date</th>\n",
       "      <th>utterance_length</th>\n",
       "      <th>utterance_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57264</td>\n",
       "      <td>9</td>\n",
       "      <td>ms. loren mooney (editor-in-chief, bicycling m...</td>\n",
       "      <td>It's a 2,200-mile race. To give some sense of ...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>False</td>\n",
       "      <td>it s a 2,200 mile race. to give some sense of ...</td>\n",
       "      <td>it s a 2,200 mile race. to give some sense of ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f8789481790&gt;</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57264</td>\n",
       "      <td>10</td>\n",
       "      <td>ms. loren mooney (editor-in-chief, bicycling m...</td>\n",
       "      <td>So for a top competitor like Lance to try to m...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>False</td>\n",
       "      <td>so for a top competitor like lance to try to m...</td>\n",
       "      <td>so for a top competitor like lance to try to m...</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f8789481790&gt;</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57264</td>\n",
       "      <td>11</td>\n",
       "      <td>neal conan, host</td>\n",
       "      <td>So in every team, presumably there's one star,...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>True</td>\n",
       "      <td>so in every team , presumably there s one star...</td>\n",
       "      <td>so in every team , presumably there s one star...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f8789481790&gt;</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57264</td>\n",
       "      <td>12</td>\n",
       "      <td>ms. loren mooney (editor-in-chief, bicycling m...</td>\n",
       "      <td>That's right. Each team has nine riders. And w...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>False</td>\n",
       "      <td>that s right. each team has nine riders. and w...</td>\n",
       "      <td>that s right. each team ha nine riders. and wh...</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f8789481790&gt;</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57264</td>\n",
       "      <td>13</td>\n",
       "      <td>neal conan, host</td>\n",
       "      <td>So slipstream, this is like drafting in car ra...</td>\n",
       "      <td>talk of the nation</td>\n",
       "      <td>how to watch the tour de france</td>\n",
       "      <td>True</td>\n",
       "      <td>so slipstream , this is like drafting in car r...</td>\n",
       "      <td>so slipstream , this is like drafting in car r...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f8789481790&gt;</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id_num  utterance_order  \\\n",
       "0         57264                9   \n",
       "1         57264               10   \n",
       "2         57264               11   \n",
       "3         57264               12   \n",
       "4         57264               13   \n",
       "\n",
       "                                             speaker  \\\n",
       "0  ms. loren mooney (editor-in-chief, bicycling m...   \n",
       "1  ms. loren mooney (editor-in-chief, bicycling m...   \n",
       "2                                   neal conan, host   \n",
       "3  ms. loren mooney (editor-in-chief, bicycling m...   \n",
       "4                                   neal conan, host   \n",
       "\n",
       "                                           utterance             program  \\\n",
       "0  It's a 2,200-mile race. To give some sense of ...  talk of the nation   \n",
       "1  So for a top competitor like Lance to try to m...  talk of the nation   \n",
       "2  So in every team, presumably there's one star,...  talk of the nation   \n",
       "3  That's right. Each team has nine riders. And w...  talk of the nation   \n",
       "4  So slipstream, this is like drafting in car ra...  talk of the nation   \n",
       "\n",
       "                             title  is_host  \\\n",
       "0  how to watch the tour de france    False   \n",
       "1  how to watch the tour de france    False   \n",
       "2  how to watch the tour de france     True   \n",
       "3  how to watch the tour de france    False   \n",
       "4  how to watch the tour de france     True   \n",
       "\n",
       "                                               clean  \\\n",
       "0  it s a 2,200 mile race. to give some sense of ...   \n",
       "1  so for a top competitor like lance to try to m...   \n",
       "2  so in every team , presumably there s one star...   \n",
       "3  that s right. each team has nine riders. and w...   \n",
       "4  so slipstream , this is like drafting in car r...   \n",
       "\n",
       "                                          lemmatized   vader        date  \\\n",
       "0  it s a 2,200 mile race. to give some sense of ...  0.0000  2010-07-12   \n",
       "1  so for a top competitor like lance to try to m...  0.9346  2010-07-12   \n",
       "2  so in every team , presumably there s one star...  0.7096  2010-07-12   \n",
       "3  that s right. each team ha nine riders. and wh...  0.9274  2010-07-12   \n",
       "4  so slipstream , this is like drafting in car r...  0.3612  2010-07-12   \n",
       "\n",
       "                        utterance_length  utterance_word_count  \n",
       "0  <function <lambda> at 0x7f8789481790>                    50  \n",
       "1  <function <lambda> at 0x7f8789481790>                    87  \n",
       "2  <function <lambda> at 0x7f8789481790>                    33  \n",
       "3  <function <lambda> at 0x7f8789481790>                   118  \n",
       "4  <function <lambda> at 0x7f8789481790>                    10  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['utterance_length'] = len(df.utterance.split())\n",
    "df['utterance_word_count'] = df.utterance.apply(str.split).apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9450e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_wordcloud(host):\n",
    "#     etc etc\n",
    "\n",
    "# h.apply(make_wordcloud)\n",
    "\n",
    "# the h is what is referred to after the apply is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c9016",
   "metadata": {},
   "source": [
    "## Is there a difference in the mean sentiment by speaker? Program? etc\n",
    "- Applied statistics-> i.e. stats testing. Is there a difference in the mean sentiment by speaker? Program? etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ead45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499385cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7418211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['Date'].dt.strftime('%b-%Y')\n",
    "\n",
    "# df['episode_date'].dt.strftime('%b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7c890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['month']=df['date'].dt.strftime('%b')\n",
    "df['year']=pd.DatetimeIndex(df['date']).year\n",
    "df=df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_index('date').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdc0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.index.year >= 2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aeff46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:'2015']\n",
    "validate = df['2016':'2017']\n",
    "test = df['2018':]\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f56a024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.index[-1:], validate.index[:1], validate.index[-1:], test.index[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.vader.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3135f",
   "metadata": {},
   "source": [
    "## Using train split from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df = train[train.is_host==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc32516",
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_df = train[train.is_host!=True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df.shape, guest_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523998e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd4b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there repeats in the host_df? \n",
    "host_df.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b431e",
   "metadata": {},
   "source": [
    "- I can see two different duplicates for steve inskeep bc of typos\n",
    "- I think this is going to fall into the arena of significantly diminishing returns, and I will not address it at this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts_with_the_most = host_df.speaker.value_counts().head(10).index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccd683",
   "metadata": {},
   "source": [
    "- This is a list of the 12 hosts with the most observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts_with_the_most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eba46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hosts_df = train[train.speaker.isin(hosts_with_the_most)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b083c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hosts_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce48924",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hosts_df.index.min(), top_hosts_df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc442f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_hosts_df.vader.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a5226",
   "metadata": {},
   "source": [
    "- Here, we have the average sentiment score for all the top hosts; as you can see, it is relatively neutral in sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b198ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(data=top_hosts_df, x='speaker',y='vader')\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09041e",
   "metadata": {},
   "source": [
    "- The mean sentiment value is awfully close for everyone here, so i'm going to stats test it with an ANOVA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a953622",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = \"Average sentiment score is the same across hosts\"\n",
    "alternative_hypothesis = \"Average sentiment score is different in at least one host of the group\"\n",
    "alpha = 0.01 # Let's be 99% certain the result we see isn't due to chance/randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9dc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df_list=[]\n",
    "for host in hosts_with_the_most:\n",
    "    x = host.split()\n",
    "    host_df_list.append(f'{x[0]}_df')\n",
    "print(host_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ac6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts_with_the_most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3e1bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's isolate our hosts\n",
    "NEAL_df = train[train.speaker == 'neal conan, host'].vader\n",
    "IRA_df = train[train.speaker ==  'ira flatow, host'].vader\n",
    "ROBERT_df = train[train.speaker == 'robert siegel, host'].vader\n",
    "STEVE_df = train[train.speaker == 'steve inskeep, host'].vader\n",
    "MELISSA_df = train[train.speaker == 'melissa block, host'].vader\n",
    "FARAI_df = train[train.speaker ==  'farai chideya, host'].vader\n",
    "RENEE_df = train[train.speaker == 'renee montagne, host'].vader\n",
    "SCOTT_df = train[train.speaker == 'scott simon, host'].vader\n",
    "DAVID_df = train[train.speaker == 'david greene, host'].vader\n",
    "RACHEL_df = train[train.speaker == 'rachel martin, host'].vader\n",
    "\n",
    "\n",
    "# GUY_df = train[train.speaker == 'guy raz, host'].vader_stopped\n",
    "# MADELEINE_df = train[train.speaker == 'madeleine brand, host'].vader_stopped\n",
    "# MICHELE_df = train[train.speaker == 'michelle norris, host'].vader_stopped\n",
    "# ALEX_df = train[train.speaker == 'alex chadwick, host'].vader_stopped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93229f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_oneway is our ANOVA test\n",
    "# See https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html for more info\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "f, p = f_oneway(NEAL_df, IRA_df, ROBERT_df, STEVE_df, MELISSA_df, FARAI_df, RENEE_df, SCOTT_df, DAVID_df, RACHEL_df)\n",
    "f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis that\", null_hypothesis)\n",
    "    print(\"We move forward with the alternative hypothesis that\", alternative_hypothesis)\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "    print(\"Evidence does not support the claim that sentiment differs from host to host\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"speaker\", y=\"vader\", kind=\"bar\", data=top_hosts_df)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41185a68",
   "metadata": {},
   "source": [
    "- Another view of the same...it looks more clear here that there is a difference, however note the small scale on the y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dbdfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693fd81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_hosts_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb07f53",
   "metadata": {},
   "source": [
    "### The conclusion to the above is that there is a statistically significant difference in sentiment in the top hosts group, even if it is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c767bed",
   "metadata": {},
   "source": [
    "### Josh's code for the hosts' words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877405c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_words = train[train.speaker.isin(hosts_with_the_most)].groupby('speaker')['lemmatized'].agg(lambda col: ' '.join(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7e1bd",
   "metadata": {},
   "source": [
    "## What's the difference in sentiment score between hosts and non-hosts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_host_df = train[train.is_host==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fccf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure\n",
    "sns.boxplot(data=train, x='is_host',y='vader')\n",
    "plt.title(\"The mean sentiment score for Hosts versus Non-Hosts\")\n",
    "plt.ylabel(\"Mean Sentiment Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b528982",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.is_host==False].vader.mean(), train[train.is_host==True].vader.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cdd3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = \"Hosts and Non-hosts have the same sentiment score\"\n",
    "alternative_hypothesis = \"Hosts and Non-hosts have different sentiment scores\"\n",
    "alpha = 0.01 # we want to be 99% sure our results aren't the result of chance/randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96853419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats testing on the same\n",
    "# anova is the wrong test!\n",
    "from scipy import stats\n",
    "\n",
    "t, p = stats.ttest_ind(host_df.vader,non_host_df.vader)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis that\", null_hypothesis)\n",
    "    print(\"We move forward with the hypothesis that\", alternative_hypothesis)\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "    print(f\"Evidence does not support the claim that\", alternate_hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c9128",
   "metadata": {},
   "source": [
    "### The average sentiment score for non-hosts is somewhat higher than for the hosts.  To be expected for a relatively neutral news outlet?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51fdca",
   "metadata": {},
   "source": [
    "## How about sentiment score by year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.resample('Y').vader.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f91bf",
   "metadata": {},
   "source": [
    "- why don't we have vader scores in 2000-2003 on yearly resampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e12c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_yearly = pd.DataFrame(train.resample('Y').vader.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_yearly.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_monthly = pd.DataFrame(train.resample('M').vader.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db450cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac045d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_monthly.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544fb872",
   "metadata": {},
   "source": [
    "- What's with all those missing sentiment scores in the early aughts?\n",
    "- We eliminated observations pre-2005, they were missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87588e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(df.resample(\"d\").vader_stopped.mean()).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da850e8",
   "metadata": {},
   "source": [
    "## By day of week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8708ca1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.groupby(train.index.weekday).vader.mean()\n",
    "# sentiment by day, 0 is monday, 6 is sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e5cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=train, x=train.index.weekday,y='vader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Monday_df = train[train.index.weekday == 0]\n",
    "Tuesday_df = train[train.index.weekday == 1]\n",
    "Wednesday_df = train[train.index.weekday == 2]\n",
    "Thursday_df = train[train.index.weekday == 3]\n",
    "Friday_df = train[train.index.weekday == 4]\n",
    "Saturday_df = train[train.index.weekday == 5]\n",
    "Sunday_df = train[train.index.weekday == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eddd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = \"Different days of the week have the same sentiment score\"\n",
    "alternative_hypothesis = \"At least one day of the week has a different sentiment score from the rest\"\n",
    "alpha = 0.01 # we want to be 99% sure our results aren't the result of chance/randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87466b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "f, p = f_oneway(Monday_df.vader,\\\n",
    "Tuesday_df.vader,\\\n",
    "Wednesday_df.vader,\\\n",
    "Thursday_df.vader,\\\n",
    "Friday_df.vader,\\\n",
    "Saturday_df.vader,\\\n",
    "Sunday_df.vader)\n",
    "\n",
    "f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b40570",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis that\", null_hypothesis)\n",
    "    print(\"We move forward with the alternative hypothesis that\", alternative_hypothesis)\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "    print(\"Evidence does not support the claim that sentiment differs from one weekday to the next\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fdcd7b",
   "metadata": {},
   "source": [
    "## And by program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c308fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.program.value_counts().index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9406a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Talk_of_the_Nation_df = train[train.program == 'talk of the nation']\n",
    "Morning_Edition_df = train[train.program == 'morning edition']\n",
    "All_Things_Considered_df = train[train.program == 'all things considered']\n",
    "News_and_Notes_df = train[train.program == 'news & notes']\n",
    "Weekend_Edition_Saturday_df = train[train.program == 'weekend edition saturday']\n",
    "Weekend_Edition_Sunday_df = train[train.program == 'weekend edition sunday']\n",
    "Day_to_Day_df = train[train.program == 'day to day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "Talk_of_the_Nation_df.resample(\"y\").vader.mean().plot(alpha=.5)\n",
    "All_Things_Considered_df.resample(\"y\").vader.mean().plot(alpha=.5)\n",
    "Morning_Edition_df.resample(\"y\").vader.mean().plot(alpha=.5)\n",
    "News_and_Notes_df.resample(\"y\").vader.mean().plot(alpha=.5)\n",
    "Day_to_Day_df.resample(\"y\").vader.mean().plot(alpha=.5)\n",
    "Weekend_Edition_Sunday_df.resample(\"y\").vader.mean().plot(alpha=.5)\n",
    "Weekend_Edition_Saturday_df.resample(\"y\").vader.mean().plot(alpha=.5)\n",
    "plt.title(\"Average Sentiment over Time, by Program\")\n",
    "plt.legend(['Talk of the Nation',\n",
    " 'All Things Considered',\n",
    " 'Morning Edition',\n",
    " 'News & Notes',\n",
    " 'Day to Day',\n",
    " 'Weekend Edition Sunday',\n",
    " 'Weekend Edition Saturday'], prop={'size': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8348a",
   "metadata": {},
   "source": [
    "- Note the programs that have gone off air\n",
    "- Also, there is some difference in sentiment from program to program\n",
    "- Weekend Edition (Sat and Sun) have higher sentiment scores--these programs try to be a little on the lighter side for the weekend\n",
    "- We're definitely starting off the day on the most pessimistic note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaee2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = \"The different programs have the same sentiment score\"\n",
    "alternative_hypothesis = \"At least one program has a different sentiment score\"\n",
    "alpha = 0.01 # we want to be 99% sure our results aren't the result of chance/randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_oneway is our ANOVA test\n",
    "# See https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html for more info\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "f, p = f_oneway(Talk_of_the_Nation_df.vader,\n",
    "All_Things_Considered_df.vader,\n",
    "Morning_Edition_df.vader,\n",
    "News_and_Notes_df.vader,\n",
    "Day_to_Day_df.vader,\n",
    "Weekend_Edition_Sunday_df.vader,\n",
    "Weekend_Edition_Saturday_df.vader,)\n",
    "f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis that\", null_hypothesis)\n",
    "    print(\"We move forward with the alternative hypothesis that\", alternative_hypothesis)\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "    print(\"Evidence does not support the claim that sentiment differs from host to host\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7e96a",
   "metadata": {},
   "source": [
    "## what about clustering?\n",
    "- There is very little continuous data here, clusering might not be possible.\n",
    "- datetime...but how usefull can that be? \n",
    "- utterance order? is that available?\n",
    "- maybe explor utterance order vs utterance length vs number of question marks or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8540c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(by=['episode_id','episode_order'])[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424fe631",
   "metadata": {},
   "source": [
    "### Ok, for the first time I'm seeing clearly how the episodes are in fact ordered by 'story' (episode_id) and then ordered by utterance within the story\n",
    "\n",
    "### This is great, bc it's what is going to make topic modeling possible down the line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac73904",
   "metadata": {},
   "source": [
    "# First...\n",
    "- Let's do a tsa model of sentiment using Prophet : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34edfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6076b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_tsa_modeling_df = pd.DataFrame(df['vader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ffefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_tsa_modeling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_prophet_df.resample('Y').mean()\n",
    "for_tsa_modeling_df.index.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe4542",
   "metadata": {},
   "source": [
    "- there is NOTHING in there fro 2000 to 2003\n",
    "- 2004 barely a thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tsa_train = for_tsa_modeling_df['2005':'2015']\n",
    "tsa_validate = for_tsa_modeling_df['2016':'2017']\n",
    "tsa_test = for_tsa_modeling_df['2018':]\n",
    "tsa_train.shape, tsa_validate.shape, tsa_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285f9b7",
   "metadata": {},
   "source": [
    "- I've dropped all observations prior to 2005 in this split due to the problem with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaea6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_train[-1:], tsa_validate[:1], tsa_validate[-1:], tsa_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d80e8d",
   "metadata": {},
   "source": [
    "- the splits look good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ff495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in prophet_train.columns:\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(tsa_train.resample('M').vader.mean())\n",
    "plt.plot(tsa_validate.resample('M').vader.mean())\n",
    "plt.plot(tsa_test.resample('M').vader.mean())\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.title('Time Series Plot of Sentiment, by Train/Validate/Test')\n",
    "plt.legend(labels = [\"Train\",\"Validate\",\"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc522546",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(tsa_train.resample('y').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217652e3",
   "metadata": {},
   "source": [
    "- There doesn't look to be any seasonality to speak of--try running the autocorrelation_plot with different resmample lengths\n",
    "- from the curriculum:\n",
    "    - \"The dashed lines are a way measure whether the observed autocorrelation is a meaningful signal or just white noise. If the majority of the peaks and valleys fall within the dashed lines, the time series is probably white noise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933649a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import Holt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet_train.dropna(axis=0, how='any')\n",
    "tsa_train.dropna(axis=0, how='any').resample('M').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11b2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsa_train[tsa_train.vader.isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662077bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsa_train['vader_stopped'] = tsa_train['vader_stopped'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5b000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sm.tsa.seasonal_decompose(tsa_train.resample('M').mean()).plot()\n",
    "\n",
    "\n",
    "# _ = sm.tsa.seasonal_decompose(tsa_train['vader_stopped'].resample('W').mean()).plot()\n",
    "\n",
    "\n",
    "# ValueError: This function does not handle missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4452b9",
   "metadata": {},
   "source": [
    "### Simple Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the empty dataframe\n",
    "eval_df = pd.DataFrame(columns=['model_type', 'target_var', 'rmse'])\n",
    "\n",
    "# function to store rmse for comparison purposes\n",
    "def append_eval_df(model_type, target_var):\n",
    "    rmse = evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var], 'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function to compute rmse\n",
    "def evaluate(target_var):\n",
    "    rmse = round(sqrt(mean_squared_error(validate[target_var], yhat_df[target_var])), 4)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(tsa_train['vader'].mean(), 4)\n",
    "\n",
    "def make_predictions():\n",
    "    yhat_df = pd.DataFrame({'vader': score}, index = validate.index)\n",
    "\n",
    "    return yhat_df\n",
    "\n",
    "yhat_df = make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and evaluate \n",
    "def plot_and_eval(target_var):\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(tsa_train[target_var].resample('M').mean(), label = 'Train', linewidth = 1)\n",
    "    plt.plot(tsa_validate[target_var].resample('M').mean(), label = 'Validate', linewidth = 1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '-- RMSE: {:.4f}'.format(rmse))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b025641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and evaluate \n",
    "def plot_and_eval_2(target_var,model_type):\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(tsa_train[target_var].resample('M').mean(), label = 'Train', linewidth = 1)\n",
    "    plt.plot(tsa_validate[target_var].resample('M').mean(), label = 'Validate', linewidth = 1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(f\"{target_var}, {model_type}\")\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '-- RMSE: {:.4f}'.format(rmse))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_eval('vader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = append_eval_df(model_type='simple_average', \n",
    "                             target_var = 'vader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebfe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bb4ad",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['vader'].rolling(3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with different periods\n",
    "\n",
    "periods = [30, 60, 90, 365]\n",
    "\n",
    "for p in periods:\n",
    "    score = round(tsa_train['vader'].rolling(p).mean().iloc[-1], 4)\n",
    "    yhat_df = make_predictions()\n",
    "    model_type = str(p) + ' day moving average'\n",
    "    eval_df = append_eval_df(model_type = model_type,\n",
    "                             target_var = 'vader'\n",
    "                            )\n",
    "    plot_and_eval_2('vader', model_type)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadcfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62538afd",
   "metadata": {},
   "source": [
    "# In case you missed it: there's something wrong with the moving average models.  Or am I wrong?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84727c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = sm.tsa.seasonal_decompose(train[col].resample('W').mean()).plot()\n",
    "# plt.show()\n",
    "\n",
    "# Still having problems loooking at seasonl decomposition due to missing valuese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa606a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_validate.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff791bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_train['vader'].resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Holt(tsa_train['vader'], exponential = False)\n",
    "# model = model.fit(smoothing_level = .1, \n",
    "#                   smoothing_slope = .1, \n",
    "#                   optimized = False)\n",
    "# yhat_items = model.predict(start = tsa_validate.index[0], \n",
    "#                            end = tsa_validate.index[-1])\n",
    "# yhat_df['vader'] = round(yhat_items, 4)\n",
    "\n",
    "# #HOLTS IS BROKEN : (\n",
    "\n",
    "# # KeyError: 'The `start` argument could not be matched to a location related to the index of the data.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat_df.head()\n",
    "# the above is returning NaNs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_and_eval('vader')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c33438",
   "metadata": {},
   "source": [
    "### Moving prophet model to its own notebook bc of the size of it (not pushing to github)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e1406",
   "metadata": {},
   "source": [
    "## The confidence intervals on the Prophet model were massive.  The sentiment observations in this data are very close together and yield rather little predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_train.groupby([tsa_train.index.year, tsa_train.index.month]).mean().unstack(0).plot()\n",
    "plt.legend(loc=(1.3,.5), bbox_to_anchor=(0.5, 0., 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c6f66",
   "metadata": {},
   "source": [
    "- Is there a trend of dipping sentiment in the summer?\n",
    "- Also, it seems like the vader scores are lower in the later years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37460be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29ffb2",
   "metadata": {},
   "source": [
    "## HOLD ON: create new splits to be used for the bag_of_words modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = wrangle.get_npr_data()\n",
    "\n",
    "\n",
    "# df.date = pd.to_datetime(df.date)\n",
    "\n",
    "\n",
    "# df['month']=df['date'].dt.strftime('%b')\n",
    "# df['year']=pd.DatetimeIndex(df['date']).year\n",
    "# df=df.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# df=df.set_index('date').sort_index()\n",
    "\n",
    "\n",
    "# df = df[df.index.year >= 2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47466469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.speaker = df.speaker.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f0ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('speaker').filter(lambda x : len(x)<=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fbf62",
   "metadata": {},
   "source": [
    "## In the next cell, i've sampled down the original df and derived all the splits based on 'rest', which was based on the small_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a78ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df.sample(10_000)\n",
    "\n",
    "counts = small_df['speaker'].value_counts()\n",
    "\n",
    "rest = small_df[~small_df['speaker'].isin(counts[counts < 3].index)]\n",
    "# df[df.groupby('speaker').filter(lambda x : len(x)<=2)] #this code doesn't work\n",
    "\n",
    "# res works perfectly : ))))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e18ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62320e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape,rest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d66d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = rest.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d30150c",
   "metadata": {},
   "source": [
    "# Trying a new approach to splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(rest.lemmatized) # is this a problem? to fit on the whole df? \n",
    "#instead of just X? Been meaning to ask a while, this is from lesson\n",
    "y = rest.is_host\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1ce05",
   "metadata": {},
   "source": [
    "## Thank god, we have a model.  Built on TF-IDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe3e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification_report(train.actual, train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X= cv.fit_transform(rest.lemmatized)\n",
    "y = rest.is_host\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b13fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1064c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e7eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52d4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f4923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ab0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281acada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b6225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab23db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b60552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3486f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "cv_train, cv_test = train_test_split(rest, test_size = .2, \\\n",
    "                                     random_state=123, stratify= rest.speaker)\n",
    "cv_train, cv_validate = train_test_split(cv_train, test_size=.3, random_state=123, \\\n",
    "                                         stratify= cv_train.speaker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train.shape, cv_validate.shape,cv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train = cv_train.drop(columns=['speaker'])\n",
    "cv_y_train = pd.DataFrame(cv_train.speaker, columns=['speaker'])\n",
    "\n",
    "cv_X_validate = cv_validate.drop(columns=['speaker'])\n",
    "cv_y_validate = pd.DataFrame(cv_validate.speaker, columns=['speaker'])\n",
    "\n",
    "cv_X_test = cv_test.drop(columns=['speaker'])\n",
    "cv_y_test = pd.DataFrame(cv_test.speaker, columns=['speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11247cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cv_X_train.shape,\n",
    "cv_y_train.shape,\n",
    "cv_X_validate.shape,\n",
    "cv_y_validate.shape,\n",
    "cv_X_test.shape,\n",
    "cv_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_bag_of_words= cv.fit_transform(cv_X_train.lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0976aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ca430",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.DataFrame(X_bag_of_words.todense(), columns=cv.get_feature_names())\n",
    "bow\n",
    "# this is way too big to visualize dense\n",
    "# ok i was able to visualize dense the rest df derived from the 100_000 sized sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_y_train.speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "cv_train = pd.DataFrame(dict(cv_y_train,actual=cv_y_train.speaker))\n",
    "cv_validate = pd.DataFrame(dict(cv_y_validate, actual=cv_y_validate.speaker))\n",
    "cv_test = pd.DataFrame(dict(cv_y_test, actual=cv_y_test.speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224949a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression().fit(bow, cv_y_train)\n",
    "\n",
    "\n",
    "cv_train['predicted'] = lm.predict(cv_X_train)\n",
    "cv_validate['predicted'] = lm.predict(cv_X_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b288b7",
   "metadata": {},
   "source": [
    "### The below cells are for TF-IDF modeling, which crashed the old macbookpro last night.  If attempting to run again, let's do so on a smaller sample of the data.\n",
    "- I was able to tfidf vectorize, just running the lm model was an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "# X_train = tfidf.fit_transform(train.lemmatized_stopped)\n",
    "# y_train = train.speaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632479e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_validate = tfidf.transform(validate.lemmatized_stopped)\n",
    "# y_validate = validate.speaker\n",
    "\n",
    "# X_test = tfidf.transform(test.lemmatized_stopped)\n",
    "# y_test = test.speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf986aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f35355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763bb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# train = pd.DataFrame(dict(actual=y_train))\n",
    "# test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "# train['predicted'] = lm.predict(X_train)\n",
    "# validate['predicted'] = lm.predict(X_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "# print('---')\n",
    "# print('Confusion Matrix')\n",
    "# print(pd.crosstab(train.predicted, train.actual))\n",
    "# print('---')\n",
    "# print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28623d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83944a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
