{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbee0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports used throughout the notebook:\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle\n",
    "import acquire\n",
    "import model\n",
    "from prepare import basic_clean, tokenize, lemmatize, stem, remove_stopwords, prep_string_data#, split_data\n",
    "import scipy as sp\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03337833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.run_modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f29566c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty evaluation dataframe\n",
    "eval_df = pd.DataFrame(columns=['Model_Type', 'Train_Accuracy','Validate_Accuracy','Accuracy_Difference', 'Beats_Baseline_By'])\n",
    "\n",
    "\n",
    "# function to store accuracy for comparison purposes\n",
    "def append_eval_df(model_type, train_accuracy, validate_accuracy):\n",
    "    d = {'Model_Type': [model_type],'Train_Accuracy':[train_accuracy], \\\n",
    "        'Validate_Accuracy': [validate_accuracy], \\\n",
    "            'Accuracy_Difference': [train_accuracy - validate_accuracy], \\\n",
    "                'Beats_Baseline_By':[validate_accuracy - 0.500614]}  # let's try to do this programatically\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)\n",
    "\n",
    "\n",
    "def run_modeling():\n",
    "    # Create an empty evaluation dataframe\n",
    "    eval_df = pd.DataFrame(columns=['Model_Type', 'Train_Accuracy','Validate_Accuracy','Accuracy_Difference', 'Beats_Baseline_By'])\n",
    "\n",
    "\n",
    "    # Define the df\n",
    "    df = wrangle.get_npr_data()\n",
    "    df['question_mark_count'] = df.utterance.str.count(r\"[\\?]\")\n",
    "    df['utterance_word_count'] = df.utterance.apply(str.split).apply(len)\n",
    "\n",
    "    # sample down due to size issuees\n",
    "    small_df = df.sample(100_000, random_state=222)\n",
    "    # counts of observations per speaker\n",
    "    counts = small_df['speaker'].value_counts()\n",
    "    # limiting our df to only speakers with 3 or more utterances. This helped wheen stratifying the splits\n",
    "    rest = small_df[~small_df['speaker'].isin(counts[counts < 3].index)]\n",
    "\n",
    "    # get initial splits based no \"rest\", which is a sampled-down df with speakers with 2 or less observations removed\n",
    "    train, validate, test = wrangle.split_data(rest)\n",
    "    print(f\"train shape is {train.shape}\")\n",
    "    print(f\"validate shape is {validate.shape}\")\n",
    "    print(f\"test shape is {test.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "    # define the features to go into the model\n",
    "    features = train.drop(columns = ['date','story_id_num','speaker','utterance','program','title',\\\n",
    "        'is_host','clean','lemmatized']).columns.to_list()\n",
    "\n",
    "    # X_ and y_ splits\n",
    "    X_train = train[features]\n",
    "    y_train = train.is_host\n",
    "\n",
    "    X_validate = validate[features]\n",
    "    y_validate = validate.is_host\n",
    "\n",
    "    X_test = test[features]\n",
    "    y_test = test.is_host\n",
    "    print(\"Basic Splits Created\")\n",
    "\n",
    "    # add a column to each basic split for the \"actual\" result (i.e. y_)\n",
    "    train['actual'] = y_train\n",
    "    validate['actual'] = y_validate\n",
    "    test['actual'] = y_test\n",
    "\n",
    "    # create splits including TF-IDF features\n",
    "    # assign the tfidf vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit/transform vectorizer on train only\n",
    "    X_train_tfidf = tfidf.fit_transform(train.lemmatized) \n",
    "    X_validate_tfidf = tfidf.transform(validate.lemmatized)\n",
    "    X_test_tfidf = tfidf.transform(test.lemmatized)\n",
    "    # add features to X_tfidf splits\n",
    "    X_train_tfidf_plusfeatures = sp.sparse.hstack((X_train_tfidf, pd.DataFrame(X_train.question_mark_count),\\\n",
    "        pd.DataFrame(X_train.utterance_order),pd.DataFrame(X_train.vader),pd.DataFrame(X_train.utterance_word_count)))\n",
    "    X_validate_tfidf_plusfeatures = sp.sparse.hstack((X_validate_tfidf, pd.DataFrame(X_validate.question_mark_count),\\\n",
    "        pd.DataFrame(X_validate.utterance_order),pd.DataFrame(X_validate.vader),pd.DataFrame(X_validate.utterance_word_count)))\n",
    "    X_test_tfidf_plusfeatures = sp.sparse.hstack((X_test_tfidf, pd.DataFrame(X_test.question_mark_count),\\\n",
    "        pd.DataFrame(X_test.utterance_order),pd.DataFrame(X_test.vader),pd.DataFrame(X_test.utterance_word_count)))\n",
    "    print('TF_IDF Splits Created')\n",
    "    # Crate splits with count vectorized features\n",
    "    # define the model #cell 156  in  the  noteebook\n",
    "    cv = CountVectorizer()\n",
    "    # fit/transform vectorizer on train only\n",
    "    X_train_cv = cv.fit_transform(train.lemmatized) \n",
    "    X_validate_cv = cv.transform(validate.lemmatized)\n",
    "    X_test_cv = cv.transform(test.lemmatized)\n",
    "    # add features to X_cv splits\n",
    "    X_train_cv_plusfeatures = sp.sparse.hstack((X_train_cv, pd.DataFrame(X_train.question_mark_count),\\\n",
    "        pd.DataFrame(X_train.utterance_order),pd.DataFrame(X_train.vader),pd.DataFrame(X_train.utterance_word_count)))\n",
    "    X_validate_cv_plusfeatures = sp.sparse.hstack((X_validate_cv, pd.DataFrame(X_validate.question_mark_count),\\\n",
    "        pd.DataFrame(X_validate.utterance_order),pd.DataFrame(X_validate.vader),pd.DataFrame(X_validate.utterance_word_count)))\n",
    "    X_test_cv_plusfeatures = sp.sparse.hstack((X_test_cv, pd.DataFrame(X_test.question_mark_count),\\\n",
    "        pd.DataFrame(X_test.utterance_order),pd.DataFrame(X_test.vader),pd.DataFrame(X_test.utterance_word_count)))\n",
    "    print('Count Vectorizer Splits Created')\n",
    "\n",
    "    # create baseline on mode (is_host == True)\n",
    "    train['baseline_pred'] = True\n",
    "    validate['baseline_pred'] = True\n",
    "    test['baseline_pred'] = True\n",
    "\n",
    "    # append to eval df\n",
    "    eval_df = append_eval_df('baseline_pred', accuracy_score(train.is_host, train.baseline_pred),accuracy_score(validate.is_host, validate.baseline_pred))\n",
    "\n",
    "    # for the modeling portion...we're gonna have to get all the lm variables togethere and disambiguate\n",
    "\n",
    "    #######################\n",
    "    # LOGISTIC REGRESSION #\n",
    "    #######################\n",
    "    print(\"Logistic Regression Beginning\")\n",
    "    # Only features\n",
    "    ###############\n",
    "    # definee model; fit on X_ and y_train\n",
    "    lm = LogisticRegression().fit(X_train, y_train)\n",
    "    # add corresponding predictions\n",
    "    train['predicted_X_just_features'] = lm.predict(X_train)\n",
    "    validate['predicted_X_just_features'] = lm.predict(X_validate)\n",
    "    test['predicted_X_just_features'] = lm.predict(X_test)\n",
    "    # append t oeval df\n",
    "    eval_df = append_eval_df('Log_Reg_Just_Features', accuracy_score(train.actual,train.predicted_X_just_features),\\\n",
    "            accuracy_score(validate.actual,validate.predicted_X_just_features))\n",
    "    # TF-IDF alone\n",
    "    ##############\n",
    "    # define model\n",
    "    lm_tfidf = LogisticRegression().fit(X_train_tfidf, y_train)\n",
    "    # add pred column\n",
    "    train['predicted_Xtfidf'] = lm_tfidf.predict(X_train_tfidf)\n",
    "    validate['predicted_Xtfidf'] = lm_tfidf.predict(X_validate_tfidf)\n",
    "    test['predicted_Xtfidf'] = lm_tfidf.predict(X_test_tfidf)\n",
    "    # append to eval df\n",
    "    eval_df = append_eval_df('Log_Reg_Just_TFIDF', accuracy_score(train.actual, train.predicted_Xtfidf),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_Xtfidf))\n",
    "    #  TF-IDF Plus Features\n",
    "    #######################\n",
    "    # define model\n",
    "    lm_tfidf_plusfeatures = LogisticRegression().fit(X_train_tfidf_plusfeatures, y_train)\n",
    "    # prdiction column\n",
    "    train['predicted_Xtfidf_plusfeatures'] = lm_tfidf_plusfeatures.predict(X_train_tfidf_plusfeatures)\n",
    "    validate['predicted_Xtfidf_plusfeatures'] = lm_tfidf_plusfeatures.predict(X_validate_tfidf_plusfeatures)\n",
    "    test['predicted_Xtfidf_plusfeatures'] = lm_tfidf_plusfeatures.predict(X_test_tfidf_plusfeatures)\n",
    "    # append to eval df\n",
    "    eval_df = append_eval_df('Log_Reg_TFIDF_Plus_Features', accuracy_score(train.actual, train.predicted_Xtfidf_plusfeatures),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_Xtfidf_plusfeatures))\n",
    "    # Count Vectorizer Alone\n",
    "    ################################\n",
    "    # model\n",
    "    lm_cv = LogisticRegression().fit(X_train_cv, y_train)\n",
    "    # prediction columns\n",
    "    train['predicted_X_cv'] = lm_cv.predict(X_train_cv)\n",
    "    validate['predicted_X_cv'] = lm_cv.predict(X_validate_cv)\n",
    "    test['predicted_X_cv'] = lm_cv.predict(X_test_cv)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('Log_Reg_CV', accuracy_score(train.actual, train.predicted_X_cv),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_X_cv))\n",
    "    # Count Vectorizer Plus Features\n",
    "    ################################\n",
    "    #model\n",
    "    lm_cv_plusfeatures = LogisticRegression().fit(X_train_cv_plusfeatures, y_train)\n",
    "    #prediction columns\n",
    "    train['predicted_X_cv_plus_features'] = lm_cv_plusfeatures.predict(X_train_cv_plusfeatures)\n",
    "    validate['predicted_X_cv_plus_features'] = lm_cv_plusfeatures.predict(X_validate_cv_plusfeatures)\n",
    "    test['predicted_X_cv_plus_features'] = lm_cv_plusfeatures.predict(X_test_cv_plusfeatures)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('Log_Reg_CV_Plus_Features', accuracy_score(train.actual, train.predicted_X_cv_plus_features),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_X_cv_plus_features))\n",
    "    print(\"LR done\")\n",
    "    #######################\n",
    "    #### DECISION TREE ####\n",
    "    #######################\n",
    "    print('Decision Tree beginning')\n",
    "    clf = DecisionTreeClassifier(max_depth = 5, random_state = 222)\n",
    "    # Only features\n",
    "    ###############\n",
    "    # define model\n",
    "    clf_just_features = clf.fit(X_train, y_train)\n",
    "    # pred cols\n",
    "    train['predicted_clf_just_features'] = clf.predict(X_train)\n",
    "    validate['predicted_clf_just_features'] = clf.predict(X_validate)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('Decision_Tree_Just_Features', accuracy_score(train.actual, train.predicted_clf_just_features),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_clf_just_features))\n",
    "    # TF-IDF alone\n",
    "    ##############\n",
    "    # define model\n",
    "    clf_tfidf = clf.fit(X_train_tfidf, y_train)\n",
    "    # pred cols\n",
    "    train['predicted_clf_tfidf'] = clf_tfidf.predict(X_train_tfidf)\n",
    "    validate['predicted_clf_tfidf'] = clf_tfidf.predict(X_validate_tfidf)\n",
    "    test['predicted_clf_tfidf'] = clf_tfidf.predict(X_test_tfidf)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('DecisionTree_Just_TFIDF', accuracy_score(train.actual, train.predicted_clf_tfidf),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_clf_tfidf))\n",
    "    #  TF-IDF Plus Features\n",
    "    #######################\n",
    "    # define model\n",
    "    clf_tfidf_plus_features = clf.fit(X_train_tfidf_plusfeatures, y_train)\n",
    "    # pred cols\n",
    "    train['CLF_predicted_Xtfidf_plusfeatures'] = clf_tfidf_plus_features.predict(X_train_tfidf_plusfeatures)\n",
    "    validate['CLF_predicted_Xtfidf_plusfeatures'] = clf_tfidf_plus_features.predict(X_validate_tfidf_plusfeatures)\n",
    "    test['CLF_predicted_Xtfidf_plusfeatures'] = clf_tfidf_plus_features.predict(X_test_tfidf_plusfeatures)\n",
    "    #append eval df\n",
    "    eval_df = append_eval_df('Decision_Tree_TFIDF_PlusFeatures', accuracy_score(train.actual, train.CLF_predicted_Xtfidf_plusfeatures),\\\n",
    "                            accuracy_score(validate.actual, validate.CLF_predicted_Xtfidf_plusfeatures))\n",
    "    # Count Vectorizer Alone\n",
    "    ################################\n",
    "    # model\n",
    "    clf_countvectorizer = clf.fit(X_train_cv, y_train)\n",
    "    # pred cols\n",
    "    train['predicted_Xcv'] = clf_countvectorizer.predict(X_train_cv)\n",
    "    validate['predicted_Xcv'] = clf_countvectorizer.predict(X_validate_cv)\n",
    "    test['predicted_Xcv'] = clf_countvectorizer.predict(X_test_cv)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('DecisionTree_Just_Countvectorizer', accuracy_score(train.actual, train.predicted_Xcv),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_Xcv))\n",
    "    # Count Vectorizer Plus Features\n",
    "    ################################\n",
    "    #model\n",
    "    clf_countvectorizer_plus_features = clf.fit(X_train_cv_plusfeatures, y_train)\n",
    "    # pred cols\n",
    "    train['predicted_Xcv_plus_features'] = clf_countvectorizer_plus_features.predict(X_train_cv_plusfeatures)\n",
    "    validate['predicted_Xcv_plus_features'] = clf_countvectorizer_plus_features.predict(X_validate_cv_plusfeatures)\n",
    "    test['predicted_Xcv_plus_features'] = clf_countvectorizer_plus_features.predict(X_test_cv_plusfeatures)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('DecisionTree_CountVectorizere_PlusFeatures', accuracy_score(train.actual, train.predicted_Xcv_plus_features),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_Xcv_plus_features))\n",
    "    print('DT done')\n",
    "\n",
    "    #######################\n",
    "    #### RANDOM FOREST ####\n",
    "    #######################\n",
    "    print('Random Forest beginning')\n",
    "    rf = RandomForestClassifier(min_samples_leaf=3,criterion='gini',max_depth=2,random_state=222)\n",
    "    # Only features\n",
    "    ###############\n",
    "    # define model\n",
    "    rf_just_features = rf.fit(X_train, y_train)\n",
    "    # pred  cols\n",
    "    train['predicted_rf_just_features'] = rf_just_features.predict(X_train)\n",
    "    validate['predicted_rf_just_features'] = rf_just_features.predict(X_validate)\n",
    "    #  append eval df\n",
    "    eval_df = append_eval_df('RandomForest_Just_Features', accuracy_score(train.actual, train.predicted_rf_just_features),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_rf_just_features))\n",
    "    # TF-IDF alone\n",
    "    ##############\n",
    "    # define model\n",
    "    rf_tfidf = rf.fit(X_train_tfidf, y_train)\n",
    "    # pred cols\n",
    "    train['predicted_rf_tfidf'] = rf_tfidf.predict(X_train_tfidf)\n",
    "    validate['predicted_rf_tfidf'] = rf_tfidf.predict(X_validate_tfidf)\n",
    "    test['predicted_rf_tfidf'] = rf_tfidf.predict(X_test_tfidf)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('RandomForest_Just_TFIDF', accuracy_score(train.actual, train.predicted_rf_tfidf),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_rf_tfidf))\n",
    "    #  TF-IDF Plus Features\n",
    "    #######################\n",
    "    # define model\n",
    "    rf_tfidf_plus_features = rf.fit(X_train_tfidf_plusfeatures, y_train)\n",
    "    # pred cols\n",
    "    train['RF_predicted_Xtfidf_plusfeatures'] = rf_tfidf_plus_features.predict(X_train_tfidf_plusfeatures)\n",
    "    validate['RF_predicted_Xtfidf_plusfeatures'] = rf_tfidf_plus_features.predict(X_validate_tfidf_plusfeatures)\n",
    "    test['RF_predicted_Xtfidf_plusfeatures'] = rf_tfidf_plus_features.predict(X_test_tfidf_plusfeatures)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('RandomForest_TFIDF_PlusFeatures', accuracy_score(train.actual, train.RF_predicted_Xtfidf_plusfeatures),\\\n",
    "                            accuracy_score(validate.actual, validate.RF_predicted_Xtfidf_plusfeatures))\n",
    "    # Count Vectorizer Alone\n",
    "    ################################\n",
    "    # model\n",
    "    rf_countvectorizer = rf.fit(X_train_cv, y_train)\n",
    "    # pred cols\n",
    "    train['predicted_Xcv'] = rf_countvectorizer.predict(X_train_cv)\n",
    "    validate['predicted_Xcv'] = rf_countvectorizer.predict(X_validate_cv)\n",
    "    test['predicted_Xcv'] = rf_countvectorizer.predict(X_test_cv)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('RandomForest_Just_CountVectorizer', accuracy_score(train.actual, train.predicted_Xcv),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_Xcv))\n",
    "    # Count Vectorizer Plus Features\n",
    "    ################################\n",
    "    #model\n",
    "    rf_countvectorizer_plus_features = rf.fit(X_train_cv_plusfeatures, y_train)\n",
    "    #pred cols\n",
    "    train['predicted_Xcv_plus_features'] = rf_countvectorizer_plus_features.predict(X_train_cv_plusfeatures)\n",
    "    validate['predicted_Xcv_plus_features'] = rf_countvectorizer_plus_features.predict(X_validate_cv_plusfeatures)\n",
    "    test['predicted_Xcv_plus_features'] = rf_countvectorizer_plus_features.predict(X_test_cv_plusfeatures)\n",
    "    # append eval df\n",
    "    eval_df = append_eval_df('RandomForest_CountVectorizer_Plus_Features', accuracy_score(train.actual, train.predicted_Xcv_plus_features),\\\n",
    "                            accuracy_score(validate.actual, validate.predicted_Xcv_plus_features))\n",
    "    print('RF done')\n",
    "\n",
    "    ######################################\n",
    "    ###### DISPLAY EVAL DF ###############\n",
    "    ######################################\n",
    "\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db202d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has 1889857 rows and 12 columns.\n",
      "train shape is (42327, 13)\n",
      "validate shape is (18141, 13)\n",
      "test shape is (15118, 13)\n",
      "Basic Splits Created\n",
      "TF_IDF Splits Created\n",
      "Count Vectorizer Splits Created\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataFrame constructor called with incompatible data and dtype: 'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   7577\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7578\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7579\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   7608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7609\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/aggregation.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(obj, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAggFuncTypeDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/aggregation.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(obj, arg, _axis)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;31m# be list-likes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_aggregator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0mnew_arg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAggFuncTypeDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a43aedf10f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_modeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-af51a4e545a1>\u001b[0m in \u001b[0;36mrun_modeling\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# append to eval df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0meval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend_eval_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baseline_pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# for the modeling portion...we're gonna have to get all the lm variables togethere and disambiguate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7767\u001b[0m         )\n\u001b[0;32m-> 7768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# pandas\\core\\apply.py:144: error: \"aggregate\" of \"DataFrame\" gets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# multiple values for keyword argument \"axis\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             return self.obj.aggregate(  # type: ignore[misc]\n\u001b[0m\u001b[1;32m    148\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   7582\u001b[0m                 \u001b[0;34mf\"incompatible data and dtype: {err}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7583\u001b[0m             )\n\u001b[0;32m-> 7584\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7586\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: DataFrame constructor called with incompatible data and dtype: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "run_modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7d582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
