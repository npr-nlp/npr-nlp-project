{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d2fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports used throughout the notebook:\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle\n",
    "import acquire\n",
    "import model\n",
    "from prepare import basic_clean, tokenize, lemmatize, stem, remove_stopwords, prep_string_data#, split_data\n",
    "import scipy as sp\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf39f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has 1889857 rows and 12 columns.\n",
      "train shape is (42327, 13)\n",
      "validate shape is (18141, 13)\n",
      "test shape is (15118, 13)\n",
      "Basic Splits Created\n",
      "TF_IDF Splits Created\n",
      "Count Vectorizer Splits Created\n",
      "Logistic Regression Beginning\n",
      "LR done\n",
      "Decision Tree beginning\n",
      "DT done\n",
      "Random Forest beginning\n",
      "RF done\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6a04d27cd2a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_modeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "eval_df, train, validate, test = model.run_modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fa826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns of eval df for use plotting below\n",
    "columns = ['Train_Accuracy', 'Validate_Accuracy','Accuracy_Difference', 'Beats_Baseline_By']\n",
    "columns\n",
    "# plot all the results, grouped by model\n",
    "eval_df.plot(x='Model_Type', y=columns, kind=\"bar\", figsize=(30,12))\n",
    "\n",
    "plt.legend#(loc=(1.01,1.2), bbox_to_anchor=(.5, 0., .5, .5))\n",
    "# ax.xaxis.set_tick_params(labelsize=20)\n",
    "# ax.yaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "# add h line for highest gross performing model\n",
    "plt.axhline(y=eval_df.Beats_Baseline_By.max())\n",
    "plt.xticks(rotation=90, fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e03525",
   "metadata": {},
   "source": [
    "## The best model in our opionion is the Logistic Regression on Count Vectorizer plus additional Features\n",
    "\n",
    "## Running this model on TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e57472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Accuracy, Countvectorizer_PlusFeatures: {:.2%}'.format(accuracy_score(train.actual, train.predicted_Xcv_train_plus_features)))\n",
    "print('---')\n",
    "# print('Confusion Matrix')\n",
    "# print(pd.crosstab(train.predicted, train.actual))\n",
    "# print('---')\n",
    "print('Validate Accuracy, Countvectorizer_PlusFeatures: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted_Xcv_validate_plus_features)))\n",
    "print('---')\n",
    "\n",
    "print('Test Accuracy, Countvectorizer_PlusFeatures: {:.2%}'.format(accuracy_score(test.actual, test.predicted_Xcv_test_plus_features)))\n",
    "print(classification_report(test.actual, test.predicted_Xcv_test_plus_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab6db9",
   "metadata": {},
   "source": [
    "### That's a 73% accuracy classifying 'is_host' (75% when running on 500_000 rows)\n",
    "### This beats baseline by 23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f0c206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
