{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32dcd607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import nltk.sentiment\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from time import strftime\n",
    "\n",
    "import wrangle\n",
    "import acquire\n",
    "from prepare import basic_clean, tokenize, lemmatize, stem, remove_stopwords, prep_string_data#, split_data\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fde5a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9b651",
   "metadata": {},
   "source": [
    "## Acquire Data\n",
    "\n",
    "Our data was acquired from kaggle.com by dowloading it directly from the [Interview: NPR Media Dialog Transcripts kaggle dataset](https://www.kaggle.com/shuyangli94/interview-npr-media-dialog-transcripts/code) website.\n",
    "\n",
    "- After downloading the relevant .csv files, our working dataset comes from two different sources (`utterances.csv` and `episodes.csv`) combined into one. \n",
    "- Our acquire script also did the following:\n",
    " - Combined dataset was put together via inner join.\n",
    " - Unnecessary and/or redundant columns were dropped or renamed.  \n",
    " - The string columns were all converted to lowercase.\n",
    " - Finally, an additional column, is_host, was created to identify whether the speaker for a specific row was an NPR host or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac88aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = acquire.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca75501",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813237b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebae00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde146f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a0e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8fc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3ca2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260e7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
